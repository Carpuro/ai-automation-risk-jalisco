{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ An√°lisis de Riesgo de Automatizaci√≥n Laboral por IA\n",
        "\n",
        "## Modelo Predictivo - Jalisco, M√©xico (2025-2030)\n",
        "\n",
        "**Autor:** Carlos Pulido Rosas  \n",
        "**Instituci√≥n:** CUCEA - Universidad de Guadalajara  \n",
        "**Programa:** Maestr√≠a en Ciencia de los Datos  \n",
        "**L√≠nea LGAC:** SMART DATA  \n",
        "**Fecha:** Noviembre 2025\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Objetivo del Proyecto\n",
        "\n",
        "Desarrollar un modelo predictivo usando **PySpark** que identifique ocupaciones con alto riesgo de sustituci√≥n laboral por Inteligencia Artificial en el estado de Jalisco, mediante an√°lisis de caracter√≠sticas ocupacionales y tendencias socioecon√≥micas.\n",
        "\n",
        "### üìä Fuentes de Datos\n",
        "\n",
        "1. **O*NET Database** - Caracter√≠sticas de ocupaciones\n",
        "2. **INEGI - ENOE** - Empleo en Jalisco\n",
        "3. **Estudios de automatizaci√≥n** (Frey-Osborne, McKinsey)\n",
        "\n",
        "### üéØ Resultados Esperados\n",
        "\n",
        "- Identificaci√≥n de ocupaciones de alto riesgo\n",
        "- Cuantificaci√≥n del impacto laboral por sector\n",
        "- Proyecciones 2025-2030\n",
        "- Recomendaciones de pol√≠tica p√∫blica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìë Tabla de Contenidos\n",
        "\n",
        "1. [Configuraci√≥n Inicial](#1-configuraci√≥n-inicial)\n",
        "2. [Carga de Datos](#2-carga-de-datos)\n",
        "3. [Exploraci√≥n de Datos](#3-exploraci√≥n-de-datos)\n",
        "4. [Preprocesamiento](#4-preprocesamiento)\n",
        "5. [Feature Engineering](#5-feature-engineering)\n",
        "6. [An√°lisis de Riesgo](#6-an√°lisis-de-riesgo)\n",
        "7. [An√°lisis por Dimensiones](#7-an√°lisis-por-dimensiones)\n",
        "8. [Visualizaciones](#8-visualizaciones)\n",
        "9. [Modelado Predictivo](#9-modelado-predictivo)\n",
        "10. [Resultados y Conclusiones](#10-resultados-y-conclusiones)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuraci√≥n Inicial\n",
        "\n",
        "### 1.1 Importaci√≥n de Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Suprimir warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Librer√≠as b√°sicas\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Agregar src al path\n",
        "sys.path.append('../src')\n",
        "\n",
        "# PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.pandas as ps\n",
        "\n",
        "# An√°lisis de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualizaci√≥n\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Configurar visualizaciones\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úì Librer√≠as importadas exitosamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Crear Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_loader import create_spark_session\n",
        "\n",
        "# Crear sesi√≥n de Spark\n",
        "spark = create_spark_session(\n",
        "    app_name=\"AI_Automation_Risk_Jalisco\",\n",
        "    memory=\"8g\"\n",
        ")\n",
        "\n",
        "print(f\"‚úì Spark Session creada\")\n",
        "print(f\"  Versi√≥n: {spark.version}\")\n",
        "print(f\"  Master: {spark.sparkContext.master}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Carga de Datos\n",
        "\n",
        "### 2.1 Datos Simulados para Pruebas\n",
        "\n",
        "Para este an√°lisis usaremos datos simulados que replican las caracter√≠sticas del Global Terrorism Database adaptado a ocupaciones laborales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_loader import load_sample_data, convert_to_pandas_api\n",
        "\n",
        "# Generar datos simulados\n",
        "# Para producci√≥n: usar load_onet_occupations() y load_enoe_jalisco()\n",
        "df_spark = load_sample_data(spark, n_occupations=200)\n",
        "\n",
        "print(f\"‚úì Datos cargados: {df_spark.count():,} ocupaciones\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Convertir a pyspark.pandas\n",
        "\n",
        "Convertimos a `pyspark.pandas` para facilitar la manipulaci√≥n con sintaxis familiar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertir a pyspark.pandas\n",
        "df = convert_to_pandas_api(df_spark)\n",
        "\n",
        "print(f\"‚úì Conversi√≥n exitosa\")\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Tipo: {type(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Exploraci√≥n de Datos\n",
        "\n",
        "### 3.1 Primeras Filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar primeras 10 ocupaciones\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Informaci√≥n General del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Informaci√≥n del dataset\n",
        "print(\"=\"*80)\n",
        "print(\"INFORMACI√ìN DEL DATASET\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nDimensiones: {df.shape}\")\n",
        "print(f\"Filas: {df.shape[0]:,}\")\n",
        "print(f\"Columnas: {df.shape[1]}\")\n",
        "\n",
        "print(\"\\nColumnas disponibles:\")\n",
        "for i, col in enumerate(df.columns, 1):\n",
        "    print(f\"  {i:2d}. {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Estad√≠sticas Descriptivas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estad√≠sticas de variables num√©ricas clave\n",
        "numeric_cols = ['routine_index', 'cognitive_demand', 'social_interaction', \n",
        "                'creativity', 'education_level', 'workers_jalisco', 'avg_salary_mxn']\n",
        "\n",
        "stats = df[numeric_cols].describe()\n",
        "print(\"\\nESTAD√çSTICAS DESCRIPTIVAS\")\n",
        "print(\"=\"*80)\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Distribuci√≥n por Sector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribuci√≥n de ocupaciones por sector\n",
        "print(\"\\nDISTRIBUCI√ìN POR SECTOR ECON√ìMICO\")\n",
        "print(\"=\"*80)\n",
        "sector_counts = df['sector'].value_counts()\n",
        "print(sector_counts)\n",
        "\n",
        "# Visualizaci√≥n\n",
        "plt.figure(figsize=(10, 6))\n",
        "sector_counts.plot(kind='bar', color='steelblue', edgecolor='black')\n",
        "plt.xlabel('Sector Econ√≥mico', fontsize=12)\n",
        "plt.ylabel('N√∫mero de Ocupaciones', fontsize=12)\n",
        "plt.title('Distribuci√≥n de Ocupaciones por Sector', fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Valores Faltantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_preprocessing import analyze_missing_values\n",
        "\n",
        "# Analizar valores faltantes\n",
        "missing_df = analyze_missing_values(df)\n",
        "\n",
        "if len(missing_df) > 0:\n",
        "    print(\"\\nCOLUMNAS CON VALORES FALTANTES:\")\n",
        "    print(\"=\"*80)\n",
        "    print(missing_df)\n",
        "else:\n",
        "    print(\"\\n‚úì No hay valores faltantes en el dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Preprocesamiento\n",
        "\n",
        "### 4.1 Pipeline de Limpieza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_preprocessing import preprocess_pipeline\n",
        "\n",
        "# Ejecutar pipeline de preprocesamiento\n",
        "df_clean = preprocess_pipeline(df, config={\n",
        "    'handle_missing': 'auto',\n",
        "    'remove_duplicates': True,\n",
        "    'filter_outliers': False\n",
        "})\n",
        "\n",
        "print(f\"\\n‚úì Preprocesamiento completado\")\n",
        "print(f\"  Filas originales: {df.shape[0]:,}\")\n",
        "print(f\"  Filas limpias: {df_clean.shape[0]:,}\")\n",
        "print(f\"  Diferencia: {df.shape[0] - df_clean.shape[0]:,} filas eliminadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Validaci√≥n de Calidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_preprocessing import validate_data_quality\n",
        "\n",
        "# Validar calidad de datos\n",
        "metrics = validate_data_quality(df_clean)\n",
        "\n",
        "print(\"\\nM√âTRICAS DE CALIDAD DE DATOS\")\n",
        "print(\"=\"*80)\n",
        "for key, value in metrics.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Feature Engineering\n",
        "\n",
        "### 5.1 Creaci√≥n de Features\n",
        "\n",
        "Crearemos m√∫ltiples √≠ndices y features derivados para el an√°lisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engineering import feature_engineering_pipeline\n",
        "\n",
        "# Ejecutar pipeline de feature engineering\n",
        "df_features = feature_engineering_pipeline(df_clean, config={\n",
        "    'create_indices': True,\n",
        "    'create_categories': True,\n",
        "    'create_ratios': True,\n",
        "    'create_temporal': True,\n",
        "    'create_sector_agg': True\n",
        "})\n",
        "\n",
        "print(f\"\\n‚úì Feature engineering completado\")\n",
        "print(f\"  Columnas originales: {df_clean.shape[1]}\")\n",
        "print(f\"  Columnas finales: {df_features.shape[1]}\")\n",
        "print(f\"  Features nuevos: {df_features.shape[1] - df_clean.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Features Creados\n",
        "\n",
        "**√çndices Base:**\n",
        "- `routine_index` - Grado de rutinizaci√≥n (0-100)\n",
        "- `cognitive_demand` - Demanda cognitiva (0-100)\n",
        "- `social_interaction` - Nivel de interacci√≥n social (0-100)\n",
        "- `creativity` - Nivel de creatividad requerida (0-100)\n",
        "- `complexity_index` - Complejidad general\n",
        "- `automation_susceptibility` - Susceptibilidad a automatizaci√≥n\n",
        "\n",
        "**Categor√≠as:**\n",
        "- `education_category` - B√°sica/Media/Superior/Posgrado\n",
        "- `salary_category` - Quintiles salariales\n",
        "- `occupation_size` - Peque√±a/Mediana/Grande\n",
        "\n",
        "**Features Temporales:**\n",
        "- `risk_projection_2026` a `risk_projection_2030`\n",
        "\n",
        "**Agregaciones por Sector:**\n",
        "- `sector_avg_risk` - Riesgo promedio del sector\n",
        "- `sector_total_workers` - Total de trabajadores del sector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar algunos features creados\n",
        "print(\"\\nNUEVOS FEATURES CREADOS:\")\n",
        "print(\"=\"*80)\n",
        "new_cols = set(df_features.columns) - set(df_clean.columns)\n",
        "for i, col in enumerate(sorted(new_cols), 1):\n",
        "    print(f\"  {i:2d}. {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. An√°lisis de Riesgo de Automatizaci√≥n\n",
        "\n",
        "### 6.1 Calcular Riesgo Base\n",
        "\n",
        "Usando metodolog√≠a basada en Frey & Osborne (2013)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from automation_analyzer import AutomationRiskAnalyzer\n",
        "\n",
        "# Crear analizador\n",
        "analyzer = AutomationRiskAnalyzer()\n",
        "\n",
        "# Calcular riesgo de automatizaci√≥n\n",
        "df_risk = analyzer.calculate_automation_risk(\n",
        "    df_features,\n",
        "    method='frey_osborne'\n",
        ")\n",
        "\n",
        "print(\"\\n‚úì Riesgo de automatizaci√≥n calculado\")\n",
        "print(\"\\nDISTRIBUCI√ìN DE RIESGO:\")\n",
        "print(\"=\"*80)\n",
        "print(df_risk['automation_risk'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Categorizar Riesgo\n",
        "\n",
        "Clasificamos ocupaciones en tres categor√≠as:\n",
        "- **Bajo Riesgo:** < 0.30\n",
        "- **Riesgo Medio:** 0.30 - 0.70\n",
        "- **Alto Riesgo:** > 0.70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorizar riesgo\n",
        "df_risk = analyzer.categorize_risk(df_risk, thresholds=(0.30, 0.70))\n",
        "\n",
        "print(\"\\nCATEGORIZACI√ìN DE RIESGO\")\n",
        "print(\"=\"*80)\n",
        "risk_counts = df_risk['risk_category'].value_counts()\n",
        "print(\"\\nConteo:\")\n",
        "print(risk_counts)\n",
        "\n",
        "print(\"\\nPorcentajes:\")\n",
        "risk_pct = df_risk['risk_category'].value_counts(normalize=True) * 100\n",
        "print(risk_pct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Top Ocupaciones en Riesgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 20 ocupaciones m√°s riesgosas\n",
        "top_risk = analyzer.identify_top_at_risk(df_risk, n=20)\n",
        "\n",
        "print(\"\\nTOP 20 OCUPACIONES CON MAYOR RIESGO\")\n",
        "print(\"=\"*80)\n",
        "print(top_risk[['occupation_name', 'sector', 'automation_risk', 'workers_jalisco']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4 Ocupaciones M√°s Seguras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 20 ocupaciones m√°s seguras\n",
        "low_risk = analyzer.identify_low_risk_occupations(df_risk, n=20)\n",
        "\n",
        "print(\"\\nTOP 20 OCUPACIONES M√ÅS SEGURAS\")\n",
        "print(\"=\"*80)\n",
        "print(low_risk[['occupation_name', 'sector', 'automation_risk']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. An√°lisis por Dimensiones\n",
        "\n",
        "### 7.1 An√°lisis por Sector Econ√≥mico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis por sector\n",
        "sector_analysis = analyzer.analyze_by_sector(df_risk)\n",
        "\n",
        "print(\"\\nAN√ÅLISIS DE RIESGO POR SECTOR\")\n",
        "print(\"=\"*80)\n",
        "print(sector_analysis.sort_values('risk_mean', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 An√°lisis por Nivel Educativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis por educaci√≥n\n",
        "education_analysis = analyzer.analyze_by_education(df_risk)\n",
        "\n",
        "print(\"\\nAN√ÅLISIS DE RIESGO POR NIVEL EDUCATIVO\")\n",
        "print(\"=\"*80)\n",
        "print(education_analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 Impacto Econ√≥mico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular impacto econ√≥mico\n",
        "impact = analyzer.calculate_economic_impact(df_risk)\n",
        "\n",
        "print(\"\\nIMPACTO ECON√ìMICO DE LA AUTOMATIZACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTotal de trabajadores: {impact['total_workers']:,}\")\n",
        "print(f\"Trabajadores en alto riesgo: {impact['workers_high_risk']:,}\")\n",
        "print(f\"Porcentaje en riesgo: {impact['pct_workers_at_risk']:.1f}%\")\n",
        "\n",
        "if impact['salary_at_risk_mxn']:\n",
        "    print(f\"\\nMasa salarial en riesgo: ${impact['salary_at_risk_mxn']:,.2f} MXN\")\n",
        "    print(f\"Porcentaje de masa salarial: {impact['pct_salary_at_risk']:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. Visualizaciones\n",
        "\n",
        "### 8.1 Distribuci√≥n del Riesgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_risk_distribution\n",
        "\n",
        "# Gr√°fico de distribuci√≥n\n",
        "plot_risk_distribution(df_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 Riesgo por Sector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_risk_by_sector\n",
        "\n",
        "# Riesgo por sector\n",
        "plot_risk_by_sector(df_risk, top_n=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3 Salario vs Riesgo (Interactivo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_salary_vs_risk\n",
        "\n",
        "# Scatter plot interactivo\n",
        "plot_salary_vs_risk(df_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4 Educaci√≥n vs Riesgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_education_vs_risk\n",
        "\n",
        "# Boxplot por nivel educativo\n",
        "plot_education_vs_risk(df_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.5 Heatmap: Sector vs Educaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_heatmap_sector_education\n",
        "\n",
        "# Mapa de calor\n",
        "plot_heatmap_sector_education(df_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.6 Treemap: Trabajadores en Riesgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_treemap_workers_at_risk\n",
        "\n",
        "# Treemap interactivo\n",
        "plot_treemap_workers_at_risk(df_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.7 Proyecciones Temporales 2025-2030"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_temporal_projections\n",
        "\n",
        "# Serie temporal de proyecciones\n",
        "plot_temporal_projections(df_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.8 Matriz de Correlaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_correlation_matrix\n",
        "\n",
        "# Correlaciones entre variables\n",
        "plot_correlation_matrix(df_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.9 Top Ocupaciones en Riesgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from visualizations import plot_top_occupations_at_risk\n",
        "\n",
        "# Barras de top ocupaciones\n",
        "plot_top_occupations_at_risk(df_risk, n=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 9. Modelado Predictivo\n",
        "\n",
        "### 9.1 Preparar Datos para Modelado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Convertir a Spark DataFrame para MLlib\n",
        "df_spark_ml = df_risk.to_spark()\n",
        "\n",
        "# Features para el modelo\n",
        "feature_cols = [\n",
        "    'routine_index',\n",
        "    'cognitive_demand',\n",
        "    'social_interaction',\n",
        "    'creativity',\n",
        "    'education_level',\n",
        "    'avg_salary_mxn'\n",
        "]\n",
        "\n",
        "# Ensamblar features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_cols,\n",
        "    outputCol='features',\n",
        "    handleInvalid='skip'\n",
        ")\n",
        "\n",
        "# Indexar target (risk_category)\n",
        "indexer = StringIndexer(\n",
        "    inputCol='risk_category',\n",
        "    outputCol='label'\n",
        ")\n",
        "\n",
        "print(\"‚úì Pipeline de features configurado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.2 Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir datos 80/20\n",
        "train_df, test_df = df_spark_ml.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"‚úì Datos divididos:\")\n",
        "print(f\"  Entrenamiento: {train_df.count():,} registros\")\n",
        "print(f\"  Prueba: {test_df.count():,} registros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.3 Entrenar Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Crear modelo Random Forest\n",
        "rf = RandomForestClassifier(\n",
        "    featuresCol='features',\n",
        "    labelCol='label',\n",
        "    numTrees=100,\n",
        "    maxDepth=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Pipeline completo\n",
        "pipeline = Pipeline(stages=[assembler, indexer, rf])\n",
        "\n",
        "# Entrenar\n",
        "print(\"Entrenando modelo Random Forest...\")\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "print(\"‚úì Modelo entrenado exitosamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.4 Evaluaci√≥n del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Hacer predicciones\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Evaluar\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol='label',\n",
        "    predictionCol='prediction',\n",
        "    metricName='accuracy'\n",
        ")\n",
        "\n",
        "print(\"\\nM√âTRICAS DEL MODELO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Otras m√©tricas\n",
        "for metric in ['weightedPrecision', 'weightedRecall', 'f1']:\n",
        "    evaluator.setMetricName(metric)\n",
        "    score = evaluator.evaluate(predictions)\n",
        "    print(f\"{metric}: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.5 Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener importancia de features\n",
        "rf_model = model.stages[-1]\n",
        "importances = rf_model.featureImportances\n",
        "\n",
        "# Crear DataFrame\n",
        "feature_importance_df = ps.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': importances.toArray()\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nIMPORTANCIA DE FEATURES\")\n",
        "print(\"=\"*80)\n",
        "print(feature_importance_df)\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance_df['feature'], feature_importance_df['importance'], color='coral', edgecolor='black')\n",
        "plt.xlabel('Importancia', fontsize=12)\n",
        "plt.title('Importancia de Caracter√≠sticas en el Modelo', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 10. Resultados y Conclusiones\n",
        "\n",
        "### 10.1 Hallazgos Clave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"HALLAZGOS CLAVE DEL AN√ÅLISIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Distribuci√≥n general\n",
        "total_high = len(df_risk[df_risk['automation_risk'] >= 0.70])\n",
        "pct_high = (total_high / len(df_risk)) * 100\n",
        "\n",
        "print(f\"\\n1. DISTRIBUCI√ìN DE RIESGO\")\n",
        "print(f\"   ‚Ä¢ {pct_high:.1f}% de ocupaciones en alto riesgo\")\n",
        "print(f\"   ‚Ä¢ {len(df_risk[df_risk['automation_risk'] < 0.30]):,} ocupaciones seguras\")\n",
        "\n",
        "# 2. Sector m√°s afectado\n",
        "top_sector = sector_analysis.iloc[0]\n",
        "print(f\"\\n2. SECTOR M√ÅS AFECTADO\")\n",
        "print(f\"   ‚Ä¢ {top_sector['sector']}\")\n",
        "print(f\"   ‚Ä¢ Riesgo promedio: {top_sector['risk_mean']:.3f}\")\n",
        "print(f\"   ‚Ä¢ Trabajadores: {top_sector['total_workers']:,}\")\n",
        "\n",
        "# 3. Correlaci√≥n educaci√≥n-riesgo\n",
        "corr = df_risk[['education_level', 'automation_risk']].corr().iloc[0, 1]\n",
        "print(f\"\\n3. EDUCACI√ìN vs RIESGO\")\n",
        "print(f\"   ‚Ä¢ Correlaci√≥n: {corr:.3f}\")\n",
        "if corr < -0.3:\n",
        "    print(f\"   ‚Ä¢ ‚úì Mayor educaci√≥n ‚Üí Menor riesgo\")\n",
        "else:\n",
        "    print(f\"   ‚Ä¢ ‚ö† Relaci√≥n d√©bil\")\n",
        "\n",
        "# 4. Impacto econ√≥mico\n",
        "print(f\"\\n4. IMPACTO ECON√ìMICO\")\n",
        "print(f\"   ‚Ä¢ Trabajadores en riesgo: {impact['workers_high_risk']:,} ({impact['pct_workers_at_risk']:.1f}%)\")\n",
        "if impact['salary_at_risk_mxn']:\n",
        "    print(f\"   ‚Ä¢ Masa salarial en riesgo: ${impact['salary_at_risk_mxn']:,.2f} MXN\")\n",
        "\n",
        "# 5. Precisi√≥n del modelo\n",
        "print(f\"\\n5. DESEMPE√ëO DEL MODELO\")\n",
        "print(f\"   ‚Ä¢ Accuracy: {accuracy:.3f}\")\n",
        "print(f\"   ‚Ä¢ Feature m√°s importante: {feature_importance_df.iloc[0]['feature']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10.2 Recomendaciones de Pol√≠tica P√∫blica\n",
        "\n",
        "**Basadas en los hallazgos del an√°lisis:**\n",
        "\n",
        "#### 1. **Sectores Prioritarios para Intervenci√≥n**\n",
        "\n",
        "Los sectores con mayor riesgo requieren programas de reconversi√≥n laboral inmediatos.\n",
        "\n",
        "#### 2. **Programas de Capacitaci√≥n**\n",
        "\n",
        "Enfocar la capacitaci√≥n en:\n",
        "- Pensamiento cr√≠tico y creativo\n",
        "- Inteligencia emocional\n",
        "- Habilidades sociales\n",
        "- Resoluci√≥n de problemas complejos\n",
        "\n",
        "#### 3. **Inversi√≥n en Educaci√≥n**\n",
        "\n",
        "La correlaci√≥n entre educaci√≥n y riesgo sugiere que la educaci√≥n superior es un factor protector.\n",
        "\n",
        "#### 4. **Monitoreo Continuo**\n",
        "\n",
        "Establecer un sistema de monitoreo para actualizar proyecciones conforme avanza la adopci√≥n de IA.\n",
        "\n",
        "#### 5. **Apoyo a Trabajadores**\n",
        "\n",
        "Programas de apoyo econ√≥mico temporal para trabajadores en transici√≥n laboral."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10.3 Limitaciones del Estudio\n",
        "\n",
        "1. **Datos simulados:** Este an√°lisis usa datos simulados. En producci√≥n se requieren datos reales de O*NET y ENOE.\n",
        "\n",
        "2. **Alcance geogr√°fico:** Limitado a Jalisco. Resultados pueden variar en otras entidades.\n",
        "\n",
        "3. **Proyecciones:** Basadas en tendencias actuales. Cambios disruptivos pueden alterar predicciones.\n",
        "\n",
        "4. **Factores externos:** No considera pol√≠ticas gubernamentales futuras o cambios econ√≥micos globales.\n",
        "\n",
        "### 10.4 Trabajo Futuro\n",
        "\n",
        "- **Datos reales:** Integrar datos completos de O*NET y ENOE\n",
        "- **An√°lisis temporal:** Incorporar series de tiempo hist√≥ricas\n",
        "- **An√°lisis geogr√°fico:** Desglose por municipios de Jalisco\n",
        "- **Modelos avanzados:** Probar Deep Learning y ensembles\n",
        "- **Validaci√≥n externa:** Contrastar con estudios internacionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Resumen Ejecutivo\n",
        "\n",
        "### Resultados Principales\n",
        "\n",
        "‚úÖ **{pct_high:.1f}%** de ocupaciones analizadas tienen alto riesgo de automatizaci√≥n\n",
        "\n",
        "‚úÖ **{impact['workers_high_risk']:,}** trabajadores en Jalisco est√°n en alto riesgo\n",
        "\n",
        "‚úÖ **{top_sector['sector']}** es el sector m√°s afectado\n",
        "\n",
        "‚úÖ Modelo predictivo alcanza **{accuracy:.1f}%** de precisi√≥n\n",
        "\n",
        "### Siguientes Pasos\n",
        "\n",
        "1. Presentar resultados a stakeholders\n",
        "2. Implementar con datos reales\n",
        "3. Desarrollar dashboard interactivo\n",
        "4. Publicar hallazgos acad√©micos\n",
        "\n",
        "---\n",
        "\n",
        "## üìû Contacto\n",
        "\n",
        "**Carlos Pulido Rosas**  \n",
        "üìß carlos.pulido.rosas@gmail.com  \n",
        "üì± +52 33 1030 5580  \n",
        "üéì CUCEA - Universidad de Guadalajara  \n",
        "üîó [GitHub](https://github.com/Carpuro/ai-automation-risk-jalisco)\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Referencias\n",
        "\n",
        "1. Frey, C. B., & Osborne, M. A. (2017). *The future of employment: How susceptible are jobs to computerisation?* Technological Forecasting and Social Change, 114, 254-280.\n",
        "\n",
        "2. McKinsey Global Institute (2023). *A Future That Works: Automation, Employment, and Productivity.*\n",
        "\n",
        "3. O*NET Program (2024). *Occupational Information Network.* U.S. Department of Labor.\n",
        "\n",
        "4. INEGI (2024). *Encuesta Nacional de Ocupaci√≥n y Empleo (ENOE).*\n",
        "\n",
        "---\n",
        "\n",
        "**Fin del An√°lisis** ‚úÖ\n",
        "\n",
        "*Notebook generado: Noviembre 2025*  \n",
        "*Versi√≥n: 1.0*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
